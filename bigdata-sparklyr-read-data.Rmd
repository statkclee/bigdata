---
layout: page
title: 빅데이터 
subtitle: "데이터(S3) 읽어오기 - R"
author:
    name: xwMOOC
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---


``` {r, include=FALSE}
# source("tools/chunk-options.R")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE,
                    comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')
```

# 윈도우 환경 AWS CLI  {#windows-aws-cli}

## 윈도우 비트 확인 [^hp-windows-bit] {#windows-aws-cli-bit}

[^hp-windows-bit]: [HP PC - 내 컴퓨터의 Windows 버전이 32비트입니까 또는 64비트입니까?](https://support.hp.com/kr-ko/document/c02020927)

AWS에 접근하는 로컬 컴퓨터 운영체제가 윈도우의 경우 Microsoft Windows에 AWS Command Line Interface 설치](https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/install-windows.html)에 
따라서 AWS CLI를 설치할 경우 가장 먼저 "Windows용 AWS CLI MSI 설치 관리자"를 다운로드 받아야 하는데 64비트와 32비트가 있다.

1. 윈도우 탐색기를 연다.
1. 좌측 메뉴 `컴퓨터`에 마우스 포인터를 위치시키고 우클릭한다.
1. 메뉴에서 "속성"을 클릭한다.
1. `컴퓨터에 대한 기본 정보 보기` &rarr; `시스템` &rarr; `시스템 종류: 64비트 운영 체제` 

혹은 윈도우 탐색기 상단 주소창에 "제어판\모든 제어판 항목\시스템"을 복사하여 붙여넣으면 `제어판 홈`에서 확인이 가능하다.

## AWS CLI 설치 {#windows-aws-cli-install}

운영체제에 맞춰 64비트 혹은 32비트 Windows용 AWS CLI MSI 설치 관리자를 다운로드 받는다.
[Windows용 AWS CLI MSI 설치 관리자(64비트) 다운로드](https://s3.amazonaws.com/aws-cli/AWSCLI64PY3.msi)받아 설치작업을 한다.

CLI는 기본적으로 `C:\Program Files\Amazon\AWSCLI`(64비트 버전) 또는 `C:\Program Files (x86)\Amazon\AWSCLI` (32비트 버전) 디렉토리에 설치됩니다.

## AWS CLI 설치 환경변수 추가 {#windows-aws-cli-install-path}

AWS CLI를 설치하게 되면 `C:\Program Files\Amazon\AWSCLI`(64비트 버전) 또는 `C:\Program Files (x86)\Amazon\AWSCLI` (32비트 버전) 디렉토리에 실행파일이 위치하게 된다.
쉘에서 AWS CLI를 바로 불러 사용할 수 있도록 등록을 해줘야 한다.
이를 환경변수 설정 작업이라고 한다.

- MSI 설치 관리자(64비트) – C:\Program Files\Amazon\AWSCLI
- MSI 설치 관리자(32비트) – C:\Program Files (x86)\Amazon\AWSCLI

AWS CLI가 설치된 디렉토리가 확인되면 다음으로 환경변수 등록작업을 한다.

1. 윈도우 키(⊞) 를 누르고 "environment variables"을 타이핑한다.
1. 환경변수 창이 뜨는 것을 확인한다.
1. `<유저명>에 대한 사용자 변수(U)`를 확인한다.
1. `변수`에서 **Path**를 선택하고 `편집(E)...`을 클릭한다.
1. 세미콜론으로 구분된 맨 마지막에 "세미콜론"으로 구분되게 64비트의 경우 `C:\Program Files\Amazon\AWSCLI` 경로명을 추가한다.
1. `확인`을 누루고 빠져나온다.

## AWS CLI 설치 확인 {#windows-aws-cli-install-path-confirm}

AWS CLI 설치 작업과 `cmd` 쉘에서 불러 사용할 수 있도록 환경설정 작업이 완료되면 
제대로 설치되어 활용이 가능한지 `cmd` 쉘에서 확인 과정을 거친다.

키보드 윈도우 키(⊞) +  `R` 누르면 실행창이 뜨고 `cmd` 를 타이핑하면 윈도우 쉘 터미널이 실행된다.

현재 컴퓨터 사용자명이 `tidyverse`로 가정하고 `where aws` 명령어로 AWS CLI 가 위치한 곳을 확인하고 
`aws --version` 명령어를 통해 정상 설치되었는지 확인한다.

``` {r aws-cli-tidyverse-windows, eval=FALSE}
Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation. All rights reserved.

C:\Users\tidyverse> aws --version
aws-cli/1.16.90 Python/3.6.0 Windows/7 botocore/1.12.80

C:\Users\tidyverse> where aws
C:\Program Files\Amazon\AWSCLI\bin\aws.cmd
```

# 윈도우 환경 `aws-shell` [^aws-shell]  {#windows-aws-cli-shell-aws}

[^aws-shell]: [An integrated shell for working with the AWS CLI.](https://github.com/awslabs/aws-shell)

[aws-shell][https://github.com/awslabs/aws-shell]을 설치하여 AWS CLI를 쉽고 편하게 사용할 수 있도록 작업한다.

`pip install aws-shell` 명령어를 통해서 `aws-shell`을 설치한다.

``` {r aws-cli-tidyverse, eval=FALSE}
C:\Users\tidyverse> pip install aws-shell
```

# AWS 키관리  {#windows-aws-cli-key}

AWS CLI를 설치하고 나서 처음 해야 할 일은 `Access Key` 및 `Secret Access Key` 그리고 기본 `리전` 및 `출력 결과`를 설정하는 것입니다. 
이유는 `Access Key` 및 `Secret Access Key` 정보만 있으면 누구나 AWS 클라우드 자원을 마음먹은대로 사용할 수 있기 때문이다.


- AWS Access Key ID [****************BDKA]:
- AWS Secret Access Key [****************zn8W]:
- Default region name [ap-northeast-2]:
- Default output format [None]:

`cmd` 윈도우 쉘에서 `aws configure` 명령어로 AWS `IAM`을 발급한 `AWS Access Key ID`,
`AWS Secret Access Key`를 설정하여 반영시킨다.
`configure list` 명령어를 통해 설정내용을 확인한다.


``` {r aws-cli-tidyverse-key, eval=FALSE}
aws> configure
AWS Access Key ID [****************BDKA]: XXXXXXXXXXXXXXXXXXXX6HOQ
AWS Secret Access Key [****************zn8W]: XXXXXXXXXXXXXXXXXXXXXXXXXhTEf
Default region name [ap-northeast-2]: ap-northeast-2
Default output format [None]: JSON

aws> configure list
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                <not set>             None    None
access_key     ****************6HOQ shared-credentials-file
secret_key     ****************hTEf shared-credentials-file
    region           ap-northeast-2      config-file    ~/.aws/config
```

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
</style>
<div class = "blue">

**Error: File association not found for extension .py** <br>
**확장명 .py에 대한 파일 연결이 없습니다.** [^file-extension-error]

[^file-extension-error]: [secretweaponsdigital, "Error: File association not found for extension .py"](https://secretweaponsdigital.wordpress.com/2015/07/23/error-file-association-not-found-for-extension-py/)

1. `cmd` 윈도우 터미널에서 `where python` 명령어로 파이썬 실행경로를 확인한다.
    - 단,  `cmd` 윈도우 터미널을 관리자 권한으로 연다.
1. 다음 명령어를 순서대로 타이핑한다.

``` {r python-extension-error, eval=FALSE}
C:\Users\tidyverse>where python
C:\ProgramData\Anaconda3\python.exe
C:\Python34\python.exe

C:\Users\tidyverse> assoc .py=py_auto_file
.py=py_auto_file

C:\Users\tidyverse> ftype py_auto_file="C:\Anaconda\python.exe" "%1" %*
py_auto_file="C:\Anaconda\python.exe" "%1" %*
```


</div>


# AWS CLI 헬로 월드 {#windows-aws-cli-hello-world}

AWS S3 버킷에 담긴 데이터를 AWS CLI를 통해 확인하여 처음으로 헬로월드를 찍어본다.
`aws-shell`을 타이핑하여 `aws>`로 프롬프트를 바꾼 후에 `s3 ls` 명령어로 
AWS S3 버킷 `tidyverse-seoul`에 포함된 디렉토리를 파악한다.

``` {r aws-cli-tidyverse-key-hello-world, eval=FALSE}
C:\Users\tidyverse> aws-shell
aws> s3 ls s3://tidyverse-seoul
                           PRE football/
                           PRE million_song/
                           PRE parquet/
                           PRE scripts/
aws> s3 ls s3://tidyverse-seoul/million_song/
2019-01-10 11:05:47          0 million_song/
2019-01-10 11:06:07  448576698 million_song/YearPredictionMSD.txt                           
```

"`Ctrl` + D"를 입력하면 `aws>` CLI를 빠져나올 수 있다.

## 자주 쓰는 AWS CLI [^aws-cli-cmd] {#windows-aws-cli-hello-world-command}

[^aws-cli-cmd]: [THESWICE, "S3"](https://m.blog.naver.com/PostView.nhn?blogId=theswice&logNo=220773070430&proxyReferer=https%3A%2F%2Fwww.google.com%2F)

AWS CIL로 자주 사용하는 명령어는 다음과 같다.

|  CLI 명령어         |      AWS S3 명령어    |
|---------------------|---------------------------------------|
| 폴더 검색           | aws s3 ls s3://dorothypaper/theswice/ |
| 파일 검색           | aws s3 ls s3://dorothypaper/theswice/file1.tar |
| 파일 다운로드(복사) | aws s3 cp s3://dorothypaper/theswice/file1.tar /data/theswice/ |
| 파일 업로드(복사)   | aws s3 cp /data/theswice/file1.tar  s3://dorothypaper/theswice/ |
| 파일 다운로드(이동) | aws s3 mv s3://dorothypaper/theswice/file1.tar /data/theswice/ |
| 파일 업로드(이동)   | aws s3 cp /data/theswice/file1.tar  s3://dorothypaper/theswice/ |
| 버킷 내 파일 복사   | aws s3 cp s3://dorothypaper/theswice/file1.tar   s3://dorothypaper/kimgn/file1.tar |
| 버킷 내 파일 이동   | aws s3 mv s3://dorothypaper/theswice/file1.tar   s3://dorothypaper/kimgn/file1.tar |
| 다수 파일 복사      | aws s3 cp /data/theswice/folder s3://dorothypaper/theswice/ --recursive |
| 폴더 복사           | aws s3 cp /data/theswice/folder s3://dorothypaper/theswice/folder --recursive |
| 특정 파일명 삭제    | aws s3 rm s3://dorothypaper/theswice/ --recursive --exclude "dorothypaper/*.sql" |
| 폴더 삭제           | aws s3 rm s3://dorothypaper/theswice/folder --recursive |
| 파일 삭제           | aws s3 rm s3://dorothypaper/theswice/file1.tar |

`iris.csv` 파일을 `s3 cp` 명령어를 통해서 `tidyverse-seoul` 버킷 `football` 디렉토리에 복사하고 이를 `s3 ls` 명령어로 확인한다.

``` {r aws-cli-tidyverse-key-hello-world-cp, eval=FALSE}
C:\Users\tidyverse> ls
iris.csv
C:\Users\tidyverse> aws-shell
aws> s3 cp iris.csv s3://tidyverse-seoul/football/
upload: .\iris.csv to s3://tidyverse-seoul/football/iris.csv
aws> s3 ls s3://tidyverse-seoul/football/
2018-11-09 17:23:29          0
2018-11-09 17:39:00       5703 anyang_2018-11-09_df.csv
2018-11-13 15:58:08       3102 anyang_2018-11-13_06:58:07_df.csv
2018-11-13 15:59:04       3102 anyang_2018-11-13_06:59:03_df.csv
2018-11-13 16:00:04       3102 anyang_2018-11-13_07:00:03_df.csv
2018-11-09 17:32:52       5703 anyang_df.csv
2019-01-17 14:47:17       3975 iris.csv
```

# S3 버킷 데이터 읽어오기 {#pyspark-read-s3-data-csv}

S3 데이터는 `.csv`, `.xlsx` 등 친숙한 파일 형태로 있을 수 있지만, 빅데이터를 효과적으로 저장하기 위해서 `.parquet` 형태로 저장되어 있기도하다. 
이를 불러들여 처리하기 위해서 두가지 조합이 필요하고 데이터 사이언스 언어(R/파이썬)에 따라 두가지 조합이 추가로 필요하다.

- S3 `.csv`: EC2 인스턴스 파이썬 판다스, **RStudio 서버**
- S3 `.parquet`: 스파크 클러스터 `pyspark`, **RStudio `sparklyr`**

<img src="fig/ec2-import-s3-data.png" alt="스파크 쥬피터 노트북" width="100%" />

- S3에 담긴 `.csv` 파일: ①
    - EC2 인스턴스 파이썬 판다스
    - **EC2 인스턴스 RStudio 서버로 가져오기**
- S3에 담긴 `.parquet` 파일: ②
    - EC2 인스턴스 파이썬 판다스
    - **EC2 인스턴스 RStudio 서버로 가져오기**
- S3에 담긴 `.csv` 파일: ③
    - EC2 스파크 클러스터 파이썬 - `pyspark`
    - **EC2 스파크 클러스터 RStudio - `sparklyr`**
- S3에 담긴 `.parquet` 파일: ④
    - EC2 스파크 클러스터 파이썬 - `pyspark`
    - **EC2 스파크 클러스터 RStudio - `sparklyr`**


# ① S3 `.csv`  {#sparklyr-read-s3-csv}
## RStudio 서버 {#sparklyr-read-s3-csv-r}

먼저 S3 버킷 `.csv` 데이터를 파이썬 판다스로 불러오는 사례를 살펴보자.
S3 EC2 인스턴스에서 AWS S3 버킷 데이터를 읽어들이기 위해서 RStudio 서버에 접속한다.


``` {r rstudio-read-s3-data, eval=FALSE}

```


# ③ S3 버킷 `.parquet` {#pyspark-read-s3-parquet-pandas}
## S3 버킷 `.parquet` &rarr; 파이썬 판다스 [^read-parquet-pandas] {#pyspark-read-s3-parquet-pandas-python} 

[^read-parquet-pandas]: [Reading and Writing the Apache Parquet Format](https://arrow.apache.org/docs/python/parquet.html)

`.parquet` 파일을 읽어오기 위해서 `pyarrow` 팩키지를 사용한다. 먼저 판다스 데이터프레임을 생성하고 이를 `pyarrow` 객체로 변환시킨다.

### `.parquet` 파일 생성 {#pyspark-read-s3-parquet-pandas-create}

먼저 판다스 데이터프레임을 생성시킨다. 
`pd.DataFrame()` 메쏘드를 사용해서 데이터프레임을 생성하고 판다스 데이터프레임을 불러읽어 `.parquet` 객체를 생성한다.

```{r make-parquet-file, eval=FALSE}
import pandas as pd
import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
from smart_open import smart_open

py_df = pd.DataFrame({'one': [-1, np.nan, 2.5],
                      'two': ['foo', 'bar', 'baz'],
                      'three': [True, False, True]},
                       index=list('abc'))

table = pa.Table.from_pandas(py_df)

table.to_pandas().head()

	one	two	three
a	-1.0	foo	True
b	NaN	bar	False
c	2.5	baz	True
```

`.parquet` 파일로 로컬 컴퓨터에 저장을 시키고 나아가 S3 버킷에 저장을 시킨다.
`pq.write_table(table, 'example.parquet')` 명령어로 앞서 생성한 파케이 객체를 `example.parquet` 파일로 저장시킨다. 그리고 나서 `/home/ubuntu/notebooks` 디렉토리 
`example.parquet` 파일이 생성된 것을 확인한다.

```{r write-parquet-file, eval=FALSE}
pq.write_table(table, 'example.parquet')
import os
print(os.getcwd())
/home/ubuntu/notebooks
! ls -al
total 36
drwxrwxr-x  3 ubuntu ubuntu  4096 Jan 14 05:41 .
drwxr-xr-x 15 ubuntu ubuntu  4096 Jan 14 01:37 ..
-rw-rw-r--  1 ubuntu ubuntu  1447 Jan 11 08:04 01_hello-spark.ipynb
-rw-rw-r--  1 ubuntu ubuntu 12324 Jan 14 05:41 02_access-s3.ipynb
-rw-rw-r--  1 ubuntu ubuntu  1559 Jan 14 05:41 example.parquet
drwxrwxr-x  2 ubuntu ubuntu  4096 Jan 14 05:29 .ipynb_checkpoints
```

### `.parquet` 파일 불러오기 {#pyspark-read-s3-parquet-pandas-read}

앞서 생성시킨 로컬 EC2 인스턴스에 저장된 `.parquet` 파일을 불러온다.
`pq.read_table()` 메쏘드를 통해 파케이 파일을 불러온다.

```{r read-local-parquet-file, eval=FALSE}
example_pq = pq.read_table('example.parquet')
example_pq.to_pandas()

one	two	three
a	-1.0	foo	True
b	NaN	bar	False
c	2.5	baz	True
```

# ③ S3 `.csv` 스파크 (psark) {#pyspark-read-s3-data-ppark}

# ④ S3 `.parquet` 스크파(spark) {#pyspark-read-s3-data-pyspark-python}



