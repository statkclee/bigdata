---
layout: page
title: 빅데이터 
subtitle: "S3 &rarr; EC2 RStudio 서버"
author:
    name: xwMOOC
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---


``` {r, include=FALSE}
# source("tools/chunk-options.R")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE,
                    comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')
```



# S3 백만송 데이터 &rarr; EC2 작업흐름 [^one-million-song-eda] [^music-recommendation] {#million-song-EDA}

[^one-million-song-eda]: [Jingying Zhou, Yibo Zhu, Yimin Zhang, Ziyue Jin, Ziyue Wu (April 27, 2016), "What is mainstream music? Million Songs Dataset Exploration"](https://zac2116.github.io/)
[^music-recommendation]: [databricks, "Predicting Song Listens Using Apache Spark"](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3175648861028866/48824497172554/657465297935335/latest.html)

빅데이터(백만송 데이터)를 분석하기 위해서 빅데이터는 클라우드 AWS S3에 저장하고, 이를 EC2에 설치한 스파크 클러스터를 통해 분석작업을 수행한다.
이를 위해서 다음과 같은 작업흐름을 갖출 수 있다.

1. S3 브라우저와 같은 FTP 프로그램을 이용하여 S3에 데이터를 전송한다.
    - [빅데이터 들어가며 - 기본기: AWS S3 파일 업로드](bigdata-pyspark-prerequisite.html#6_aws_s3_%ED%8C%8C%EC%9D%BC_%EC%97%85%EB%A1%9C%EB%93%9C) 참조
1. EC2 인스턴스에 우선 로컬 스파크 클러스터를 구축한다.
1. 로컬 PC에서 EC2 인스턴스에 RStudio 서버 IDE 로 접속하여 분석작업을 수행한다.

<img src="fig/s3-ec2-rstudio-workflow.png" alt="백만송 S3 업로드" width="67%" />

## 한걸음 더 들어갑니다. {#million-song-EDA-one-step-forward}

한걸음 더 들어가 S3 버킷에 데이터가 저장되어 있는 상태에서 데이터 분석에 필요한 연산작업을 
EC2 인스턴스를 생성시켜 이를 통해서 추진하는 것이다.
EC2 인스턴스에 명령을 내리기 위해서 외부 로컬 컴퓨터에서 웹브라우저를 통해 접속하게 된다.

<img src="fig/aws-import-s3-ec2-sparklyr.png" alt="S3-EC2-terminal-toolchain" width="77%" />


# EC2에서 S3 접근 [^aws.s3-read-file] {#million-song-s3-access}

[^aws.s3-read-file]: [Reading a csv file from S3:// in R #201](https://github.com/cloudyr/aws.s3/issues/201)

EC2에서 S3로 접근하려면 `aws.s3` 팩키지를 사용한다. S3에 접근하기 위해서 `AWS_ACCESS_KEY_ID`, 
`AWS_SECRET_ACCESS_KEY`, `AWS_DEFAULT_REGION`을 설정한다. 
설정된 내용이 제대로 되었는지는 `bucketlist()` 함수로 확인되면,
`s3read_using()` 함수를 사용해서 CSV 파일을 EC2 컴퓨터에 데이터프레임으로 가져온다.

``` {r access-to-S3-from-ec2, eval=FALSE}
library(aws.s3)
library(tidyverse)

# 2. S3 버킷 접근을 위한 키값 설정
Sys.setenv("AWS_ACCESS_KEY_ID" = "A************************",
           "AWS_SECRET_ACCESS_KEY" = "V*************************",
           "AWS_DEFAULT_REGION" = "ap-northeast-2")

# 3. S3 버킷 헬로월드
## 3.1. 버킷 확인
bucketlist()

## 3.2. 데이터 가져오기
msong_df <- s3read_using(read_csv, object = "s3://<버킷명>/million_song/YearPredictionMSD.txt", col_names = FALSE)

## 3.3. 데이터 확인
msong_df

# A tibble: 515,345 x 91
      X1    X2      X3    X4     X5      X6      X7     X8      X9   X10    X11     X12    X13   X14   X15   X16   X17   X18
   <int> <dbl>   <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl> <dbl>  <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
 1  2001  49.9  21.5    73.1   8.75 -17.4   -13.1   -25.0  -12.2    7.83 -2.47   3.32   -2.32  10.2   611.  951.  698.  409.
 2  2001  48.7  18.4    70.3  12.9  -10.3   -24.8     8.77  -0.920 18.8   4.59   2.22    0.340 44.4  2057.  605.  457.  777.
 3  2001  51.0  31.9    55.8  13.4   -6.58  -18.5    -3.28  -2.35  16.1   1.40   2.74    0.828  7.47  700. 1016.  594.  356.
 4  2001  48.2  -1.90   36.3   2.59   0.972 -26.2     5.05 -10.3    3.55 -6.36   6.63   -3.35  37.6  2174.  697.  459.  743.
 5  2001  51.0  42.2    67.1   8.47 -15.9   -16.8   -12.5   -9.38  12.6   0.936  1.61    2.19  47.3   894.  810.  319.  435.
 6  2001  50.5   0.316  92.4  22.4  -25.5   -19.0    20.7   -5.20   3.64 -4.69   2.50   -3.02   7.69 1005.  785.  592.  496.
 7  2001  50.6  33.2    50.5  11.6  -27.2    -8.78  -12.0   -9.54  28.6   8.25  -0.437   5.66  11.1  1081. 1231. 1302.  953.
 8  2001  48.3   8.98   75.2  24.0  -16.0   -14.1     8.12  -1.88   7.47  1.18   1.47   -6.34   8.40 1620. 1762.  715. 1116.
 9  2001  49.8  34.0    56.7   2.90  -2.92  -26.4     1.71  -0.556 22.1   7.44  -0.0358  1.67  46.0   790.  608.  249.  288.
10  2007  45.2  46.3   -40.7  -2.48   1.21   -0.653  -6.96 -12.2   17.0   2.00  -1.88    9.85  25.6  1905. 3676. 1977.  913.
# ... with 515,335 more rows, and 73 more variables: X19 <dbl>, X20 <dbl>, X21 <dbl>, X22 <dbl>, X23 <dbl>, X24 <dbl>,
#   X25 <dbl>, X26 <dbl>, X27 <dbl>, X28 <dbl>, X29 <dbl>, X30 <dbl>, X31 <dbl>, X32 <dbl>, X33 <dbl>, X34 <dbl>, X35 <dbl>,
#   X36 <dbl>, X37 <dbl>, X38 <dbl>, X39 <dbl>, X40 <dbl>, X41 <dbl>, X42 <dbl>, X43 <dbl>, X44 <dbl>, X45 <dbl>, X46 <dbl>,
#   X47 <dbl>, X48 <dbl>, X49 <dbl>, X50 <dbl>, X51 <dbl>, X52 <dbl>, X53 <dbl>, X54 <dbl>, X55 <dbl>, X56 <dbl>, X57 <dbl>,
#   X58 <dbl>, X59 <dbl>, X60 <dbl>, X61 <dbl>, X62 <dbl>, X63 <dbl>, X64 <dbl>, X65 <dbl>, X66 <dbl>, X67 <dbl>, X68 <dbl>,
#   X69 <dbl>, X70 <dbl>, X71 <dbl>, X72 <dbl>, X73 <dbl>, X74 <dbl>, X75 <dbl>, X76 <dbl>, X77 <dbl>, X78 <dbl>, X79 <dbl>,
#   X80 <dbl>, X81 <dbl>, X82 <dbl>, X83 <dbl>, X84 <dbl>, X85 <dbl>, X86 <dbl>, X87 <dbl>, X88 <dbl>, X89 <dbl>, X90 <dbl>,
#   X91 <dbl>
```








